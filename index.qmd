---
title: |
   HEADS 22-26
      [![image alt >2](./images/fmup.png)](https://sigarra.up.pt/fmup/en/web_page.inicial)
      [![image alt >1](./images/heads.png)](https://heads.med.up.pt/en/)
   
subtitle: "ANALYZE - Final Assignment"
date: "2022/12/31"
author:
  - Carlos Matos
  - Vera Pinheiro
execute:
  eval: true #runs the code in the chunk
  echo: false #does not show the code in the final output
  include: false #still evals, but prevents code and results from appearing in the final output
format: 
  html:
    page-layout: full
css: styles.css
---


# Risk factors for cervical cancer: a case study

::: panel-tabset
## Package imports
```{r packages, echo = TRUE, include = TRUE, message = FALSE}

# Importing the necessary packages

library(rio)          # Import function for multiple file formats
library(tidyverse)    # Data wrangling and visualization
library(janitor)      # Data examining and cleaning functions
library(summarytools) # Descriptive statistics
library(kableExtra)   # Display and format html tables
library(broom)        # Functions to tidy outputs
library(tidymodels)   # Modeling and statistical analysis that share the underlying philosophy of the tidyverse.
library(dotwhisker)   # Dot-and-Whisker Plots of Regression Results
library(MASS)         # Used for the stepAIC function for automatic variable selection
library(caret)        # For Classification and Regression Training
library(pROC)         # To create ROC curves

```


```{r setup_chunk}

knitr::opts_chunk$set(fig.width = 12, fig.height = 8)

```

## Data Import

```{r data_import, echo = TRUE, include = TRUE, message = FALSE, warning=FALSE}
#Immport the dataset directly from the website
df <- rio::import(file = "https://archive.ics.uci.edu/ml/machine-learning-databases/00383/risk_factors_cervical_cancer.csv",
                  setclass = "tibble") %>%
  janitor::clean_names() 

#Pre-process the dataset
df <- df %>%
  mutate(across(everything(), as.numeric)) %>% #forces "?" to NA
  mutate(across(c(10, 12, 14:25, 29:36), ~ factor(., levels = c(0,1), labels = c("No","Yes")))) %>% #Convert the appropriate columns to factor
  #mutate(across(c(6, 7, 9, 11), as.numeric)) %>% #Convert the appropriate columns to numeric
  mutate(across(c(1:5, 8, 13, 26:28), as.integer)) %>% #Convert the appropriate columns to integer
  rename_all(.funs = ~ str_replace_all(names(df),"st_ds","stds")) 

str(df)
```


## Descriptive statistics

```{r descriptive_stats,echo = TRUE, include = TRUE, message = FALSE, warning=FALSE}
summarytools::dfSummary(df) %>% 
  print(method = "render")

#TODO: some text interpreting descriptive analytics
## dx_cancer will be our target variable. Other target variables will be discarded.
## stds_cervical_condylomatosis and stds_aids only have one level (no positive cases)

```

## Univariate Regression

```{r univariate_analysis, echo = TRUE, include = TRUE, message = FALSE, warning=FALSE}

#In subsequent analyses our outcome variable will be "dx_cancer"
outcome_var <- "dx_cancer"

# Analysis to study association between a cancer diagnosis and each other variable, one at a time
# Model of the type dx_cancer ~ other_var

#* We created a function that, given a dataset, an outcome variable and other variable in the dataset, 
#* returns the appropriate logistic regression. Accepts the optional boolean argument "exponentiate", 
#* that allows the user to choose between exponentiated parameters or not.

# Function output includes the terms of the regression, point estimate, std.error, test statistic, p.value, confidence interval and variables used in the model. If some error occurs, NA is returned.


fit_logistic_model <- function(dataset, outcome_var, other_var, exponentiate = TRUE) {
  out <- tryCatch(
    {
      #get dataset name passed as string
      dataset <- get(dataset)
      #fit the model
      parsnip::fit(logistic_reg(), as.formula(paste(outcome_var, " ~ ", other_var)), data = dataset) %>% 
        broom::tidy(exponentiate = exponentiate, conf.int = T) %>% 
        mutate(outcome_var = outcome_var,
               other_var = other_var)
    },
    error = function(cond) {
      return(tibble('term'=NA, 'estimate'=NA, 'std.error'=NA, 'statistic'=NA, 'p.value'=NA, 'conf.low'=NA, 'conf.high'=NA, 
                    'outcome_var' = outcome_var, 'other_var' = other_var))
    }
  )
  return(out)
}

# Apply the created function to a list that contains all the variables in the dataset (not including target variables other than the desired one)
logistic_results <- pmap_dfr(.l = as.list(crossing("df",
                                                   outcome_var,
                                                   names(df[c(1:28,30:31)]))),
                             .f = ~ fit_logistic_model(dataset = ..1,
                                                       outcome_var = ..2,
                                                       other_var = ..3,
                                                       exponentiate = T))

# Add a variable with values "sig" or "not sig", depending on whether the confidence interval includes the value 1 (using the exponentiated values of the parameters)
logistic_results2 <- logistic_results %>% 
  mutate(sig = ifelse(p.value < 0.05, "sig","not sig")) %>% 
  filter(term != "(Intercept)") 

#INTERPRETATION:
# Variables significantly associated with dx_cancer are:
## age, dx_hpv, iud, iud_years, smokes_packs_year
## Older age, having HPV, having IUD, using IUD for longer and higher intensity of smoking are associated with higher odds of having a cancer diagnosis.


# Dot and whisker plot of all univariate models, condensed in a single plot

## Some CIs are absurdly large, so in this step we process that data to hide those variables
log_res_plot <- logistic_results2 %>% 
  #mutate(conf.high = ifelse(conf.high > 6 | is.na(conf.high), 6, conf.high)) %>% # processing to show large CIs as -20 to 20, just for the plot
  # mutate(conf.low = ifelse(conf.low < 0 | is.na(conf.low), 0.1, conf.low)) %>% 
  # filter(conf.high <= 6 & conf.low >= 0.1) %>% 
  mutate(sig = ifelse(sig == "sig", "red","black"))

#Plot to show the OR and CI (dot and whisker plot), for each variable as a predictor of dx_cancer
log_res_plot %>% # excluding extremely large CIs
  dwplot(dot_args = list(size = 2, aes(color = log_res_plot$sig)),
         whisker_args = list(aes(color = log_res_plot$sig)),
         vline = geom_vline(xintercept = 1, colour = "grey50", linetype = 2)) +
  scale_color_manual(paste0(as.character("\u03B1")," = 0.05"), breaks = c("red", "black"), values = c("red","black"),
                       labels = c("Significant", "Not significant")) +
  scale_x_log10(breaks = c(0.1, 0.5, 1, 2, 6, 9, 12), minor_breaks = NULL, limits = c(0.1,12)) +
  #xlim(c(0.1, 6))+
  theme(
    plot.title = element_text(face = "bold"),
    legend.position = c(0.7, 0.01),
    legend.justification = c(0, 0),
    legend.background = element_rect(colour = "grey80"),
    legend.title.align = .5
  )  +
  labs(title = "Parameters from each univariate logistic regression",
       subtitle = "Models in the format dx_cancer ~ other_var",
       caption = "The plot shows exponentiated parameter values. \n Intercepts are omitted for each univariate model. \n Values lower than 0.1 and higher than 12 are omitted from the plot.",
       x = "OR (log10 scale)") +
  theme(axis.text.y = element_text(color = rev(log_res_plot$sig)))

# Print a table with summary measures from univariate models
# For very high upper CI values, replace by Inf to improve table readability
logistic_results2 %>% 
  dplyr::select(-c(outcome_var, other_var)) %>%
  dplyr::mutate(conf.high = ifelse(conf.high>100000, Inf, conf.high)) %>% 
  mutate(across(where(is.numeric), ~scales::number(., accuracy = 0.001))) %>% 
  kbl() %>% 
  kable_classic() 

```

## Multivariate Regression Model 

```{r multivariate_model, echo = TRUE, include = TRUE, message = FALSE, warning=FALSE}

# Variable seleciton methods:
## include all variables significantly associated with the outcome in the univariate model
## Stepwise approach


#NB: we need to remove variables that have only one level with values
## stds_cervical_condylomatosis and stds_aids

df_complete_cases <- df %>% 
  dplyr::select(-stds_time_since_first_diagnosis, -stds_time_since_last_diagnosis) %>% # lot of missings in these variables, we might lose a lot of information
  dplyr::select(- c(stds_cervical_condylomatosis, stds_aids, 27, 31:34)) %>% # variables with only 1 level and target variables other than the one we want
  drop_na() # we can't have missing values for the stepAIC function

#Mass package, as in class
model.logit <- glm(dx ~ ., data = df_complete_cases, family = "binomial")
model.step <- stepAIC(model.logit, direction = "backward", trace = FALSE)

summary(model.step)

## The model obtained from automatic variable selection with stepAIC seems to make little sense from a biological perspective.
## Why include some stds and not others?
## we are including 10 variables, and we have 18 positive cases. Maybe we are memorizing the data, instead of generalizing.


## Based on this, we opted to select a model with all variables that were significant in the univariate analysis

# Model including variables that were significant in the univariate analyses
## NB: here we are using df instead of df_complete_cases


#Multivariate logistic regression
multivariate_model <- glm(formula = dx ~ age + dx_hpv + iud + iud_years + smokes_packs_year, 
            family = "binomial", data = df)

summary(multivariate_model)

#Exponentiated parameters and confidence intervals
broom::tidy(multivariate_model, exponentiate = T, conf.int = T) %>% 
  mutate(across(where(is.numeric), ~scales::number(., accuracy = NULL))) %>% 
  kbl() %>% 
  kable_classic() 



```


## Model Evaluation

```{r model_evaluation, echo = TRUE, include = FALSE, message = FALSE, warning=FALSE}

#Set seed for reproducibility
set.seed(42)

#Prepare fataset for model evaluation
prep_dataset <- df %>%
  dplyr::select(-c(dx:biopsy)) %>% #drop unused target variables
  dplyr::select(-stds_time_since_first_diagnosis, -stds_time_since_last_diagnosis) %>%  # lot of missings in these variables
  drop_na()


# Holdout a validation set, by defining the indices of the training set
training.index <- createDataPartition(prep_dataset$dx_cancer, p=0.8, list=FALSE)
validation <- prep_dataset[-training.index,]
dataset <- prep_dataset[training.index,]


#Included validations:
# 20% hold-out validation
# Multiple 20% hold-out validation (25x)
# 2-fold cross validation
# 10-fold cross validation
# 25 times 10-fold cross validation
# Leave-one-out validation
# Bootstrap validation

# We use the ROC metric

# Tibble with all types of evaluation methods to explore
control_params <- tibble(method = c("LGOCV","LGOCV","cv","cv","repeatedcv","LOOCV","boot_all"),
                         p = c(0.8,0.8,NA,NA,NA,NA,NA),
                         number = c(1,25,2,10,10,NA,25),
                         repeats = c(NA,NA,NA,NA,25,NA,NA),
                         desc = c("20% hold-out validation", "Multiple 20% hold-out validation (25x)", "2-fold cross validation","10-fold cross validation", "25 times 10-fold cross validation","Leave-one-out validation","Bootstrap validation"))

# Iterate over control_params to create a trainControl function

train_controls <- control_params %>%
  pmap(.f = ~ trainControl(method = ..1, p = ..2, number = ..3, repeats = ..4, summaryFunction=twoClassSummary, classProbs=T, savePredictions = T))

rpart <- train_controls %>%
  map(.f = ~ train(dx_cancer ~ ., data=dataset, method = "rpart", metric = "ROC", trControl = .x))

naive_bayes <- train_controls %>%
  map(.f = ~ train(dx_cancer ~ ., data=dataset, method = "naive_bayes", metric = "ROC", trControl = .x))

nnet <- train_controls %>%
  map(.f = ~ train(dx_cancer ~ ., data=dataset, method = "nnet", metric = "ROC", trControl = .x))

names(rpart) <- names(naive_bayes) <- names(nnet) <- control_params$desc

#TODO: ROC curves for these models


```


```{r model_evaluation_plots, echo = TRUE, include = TRUE, message = FALSE, warning=FALSE}

# Custom function to plot ROC curves for the 3 selected methods (Decision tree, naive bayes and neural network) in the same plot, for a given validation method
custom_roc_plot <- function(validation_type) {
  
  #get roc data
  nnet_roc <- pROC::roc(nnet[[validation_type]]$pred$obs, nnet[[validation_type]]$pred$Yes)
  naive_bayes_roc <- pROC::roc(naive_bayes[[validation_type]]$pred$obs, naive_bayes[[validation_type]]$pred$Yes)
  rpart_roc <- pROC::roc(rpart[[validation_type]]$pred$obs, rpart[[validation_type]]$pred$Yes)
  
  
  #sensitivities and specificities
  nnet_data <- tibble(Sensitivity = nnet_roc$sensitivities,
                 Specificity = nnet_roc$specificities,
                 Method="nnet")
  naive_bayes_data <- tibble(Sensitivity = naive_bayes_roc$sensitivities,
                 Specificity = naive_bayes_roc$specificities,
                 Method="nb")
  rpart_data <- tibble(Sensitivity = rpart_roc$sensitivities,
                 Specificity = rpart_roc$specificities,
                 Method="rpart")
  
  all_data <- bind_rows(nnet_data, naive_bayes_data, rpart_data)
  
  # nnet_auc <- c("nnet" = nnet_roc$auc)
  # naive_bayes_auc <- c("nb" = naive_bayes_roc$auc)
  # rpart_auc <- c("rpart" = rpart_roc$auc)
  
  #all_auc <- c("nnet" = nnet_roc$auc, "nb" = naive_bayes_roc$auc, "rpart" = rpart_roc$auc)
  all_auc <- tibble(names = c("nnet","nb","rpart"),
                    values = c(nnet_roc$auc,naive_bayes_roc$auc, rpart_roc$auc))
  
  #Return the plot
  return(
    ggplot() +
      geom_line(data = all_data, aes(y = Sensitivity, x = 1 - Specificity, group=Method, color=Method)) +
      geom_abline(intercept = 0, color="gray") +
      geom_text(aes(x=0.9, y = 0.65, label ="AUC:")) +
      geom_text(data = all_auc, aes(x=rep(0.9,3), y = c(0.45, 0.55, 0.35), color = names, label=scales::number(values))) +
      labs(title = validation_type)
  )
}

#We now explore all the selected validation methods
control_params$desc %>% 
  map(custom_roc_plot)

# 
# #get roc data
# nnet_roc <- pROC::roc(nnet[[3]]$pred$obs, nnet[[3]]$pred$Yes)
# naive_bayes_roc <- pROC::roc(naive_bayes[[3]]$pred$obs, naive_bayes[[3]]$pred$Yes)
# rpart_roc <- pROC::roc(rpart[[3]]$pred$obs, rpart[[3]]$pred$Yes)
# 
# 
# #sensitivities and specificities
# nnet_data <- tibble(Sensitivity = nnet_roc$sensitivities,
#                Specificity = nnet_roc$specificities,
#                Method="nnet")
# naive_bayes_data <- tibble(Sensitivity = naive_bayes_roc$sensitivities,
#                Specificity = naive_bayes_roc$specificities,
#                Method="nb")
# rpart_data <- tibble(Sensitivity = rpart_roc$sensitivities,
#                Specificity = rpart_roc$specificities,
#                Method="rpart")
# 
# all_data <- bind_rows(nnet_data, naive_bayes_data, rpart_data)
# 
# # nnet_auc <- c("nnet" = nnet_roc$auc)
# # naive_bayes_auc <- c("nb" = naive_bayes_roc$auc)
# # rpart_auc <- c("rpart" = rpart_roc$auc)
# 
# all_auc <- c("nnet" = nnet_roc$auc, "nb" = naive_bayes_roc$auc, "rpart" = rpart_roc$auc)
# all_auc <- tibble(names = c("nnet","nb","rpart"),
#                   values = c(nnet_roc$auc,naive_bayes_roc$auc, rpart_roc$auc))
# 
# ggplot() +
#   geom_line(data = all_data, aes(y = Sensitivity, x = 1 - Specificity, group=Method, color=Method)) +
#   geom_abline(intercept = 0, color="gray") +
#   geom_text(aes(x=0.9, y = 0.65, label ="AUC:")) +
#   geom_text(data = all_auc, aes(x=rep(0.9,3), y = c(0.45, 0.55, 0.35), color = names, label=scales::number(values))) +
#   labs(title = control_params$desc[1])


```


## Info

```{r final_notes, echo = TRUE, include = TRUE, message = FALSE, warning=FALSE}
si <- sessionInfo()
si$loadedOnly <- NULL
si

#TODO: do not forget to include a seed at each necessary step!!!
#TODO: e.     Comentário sobre como sua abordagem e solução final precisariam de ser diferentes se aplicadas ao conjunto de dados drasticamente maior, discutindo sobre as implicações de ter conjuntos de dados “muito grandes”.

```



:::
